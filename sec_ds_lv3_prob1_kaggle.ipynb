{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "765c0422",
   "metadata": {},
   "source": [
    "# 문제 6\n",
    "\n",
    "[Kaggle 형] train_prob.csv로 문제 failure 예측하는 모델을 만들고, \n",
    "\n",
    "test_prob.csv에 대한 failure가 1일 확률 예측하여 다음과 같은 형식의 answer6.csv를 만들어라. \n",
    "\n",
    "측정 지표는 AUC(area under of ROC curve)이다. id 는 테스트 케이스의 id 이고, failure에는 failure가 1이 될 확률이다.\n",
    "\n",
    "id,failure\n",
    "\n",
    "16115, 0.1\n",
    "\n",
    "16116, 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "422cead3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 0.25.1\n",
      "numpy 1.18.5\n",
      "sklearn 0.21.3\n",
      "scipy 1.5.2\n",
      "mlxtend 0.15.0.0\n",
      "statsmodels 0.11.1\n"
     ]
    }
   ],
   "source": [
    "# 실행 환경 확인\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import statsmodels\n",
    "import mlxtend\n",
    "import sys\n",
    "\n",
    "print(sys.version)\n",
    "for i in [pd, np, sklearn, scipy, mlxtend, statsmodels]:\n",
    "    print(i.__name__, i.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3707456",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_prob.csv', index_col='id')\n",
    "df_test = pd.read_csv('test_prob.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc1e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치를 처리하기 전에,\n",
    "# 결측 여부가 failure를 예측하는데, 유용할 만하다고 도출된\n",
    "# measurement_3, measurement_5의 결측 여부만 남깁니다.\n",
    "df_train[['na_1', 'na_2']] = df_train[['measurement_3', 'measurement_5']].isna()\n",
    "df_test[['na_1', 'na_2']] = df_test[['measurement_3', 'measurement_5']].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e86c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    5765\n",
       "E    5343\n",
       "B    5250\n",
       "A    5100\n",
       "Name: product_code, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['product_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db3f336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D    5112\n",
       "Name: product_code, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['product_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5b3839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer# 구문을 사용하여 실험 단계인 모듈을 활성화하고, \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X_imp = ['measurement_{}'.format(i) for i in range(3, 10)] + ['measurement_17']\n",
    "# train에 등장하지 않은 수준이 있습니다, test를 포함하여 결측처리 모델을 만듭니다.\n",
    "s_imp = pd.concat([\n",
    "        df_train[X_imp + ['product_code']],\n",
    "        df_test[X_imp + ['product_code']]\n",
    "], axis=0).groupby('product_code')\\\n",
    ".apply(\n",
    "    lambda x: IterativeImputer(estimator=LinearRegression(),random_state=123).fit(x[X_imp])\n",
    ")\n",
    "# train에 적용합니다.\n",
    "df_train[X_imp] = df_train[X_imp + ['product_code']]\\\n",
    "            .groupby('product_code')\\\n",
    "            .apply(\n",
    "                lambda x: pd.DataFrame(s_imp.loc[x.name].transform(x[X_imp]), index=x.index, columns=X_imp)\n",
    "            )\n",
    "# test에 적용합니다.\n",
    "df_test[X_imp] = df_test[X_imp + ['product_code']]\\\n",
    "            .groupby('product_code')\\\n",
    "            .apply(\n",
    "                lambda x: pd.DataFrame(s_imp.loc[x.name].transform(x[X_imp]), index=x.index, columns=X_imp)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70970752",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = ['measurement_{}'.format(i) for i in range(10, 17)]\n",
    "# 역시 train에 등장하지 않은 수준을 처리하기 위해 합치니다.\n",
    "df_mean = pd.concat([\n",
    "            df_train[['product_code'] + X_mean],\n",
    "            df_test[['product_code'] + X_mean]\n",
    "        ]).groupby('product_code')[X_mean].agg('mean')\n",
    "\n",
    "df_train[X_mean] = df_train.groupby('product_code')[X_mean]\\\n",
    "            .apply(lambda x: pd.DataFrame(x.fillna(df_mean.loc[x.name]), index=x.index, columns=x.columns))\n",
    "df_test[X_mean] = df_test.groupby('product_code')[X_mean]\\\n",
    "            .apply(lambda x: pd.DataFrame(x.fillna(df_mean.loc[x.name]), index=x.index, columns=x.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71f45470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['loading'] = df_train['loading'].fillna(df_train['loading'].mean())\n",
    "# loading은 train에서의 평균으로 결측치를 처리합니다.\n",
    "df_test['loading'] = df_test['loading'].fillna(df_train['loading'].mean())\n",
    "df_train.isna().sum().sum(), df_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a58e27d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통으로 사용할 만한 요소입니다.\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, GroupKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=123, shuffle=True) # 5겹의 층화교차검증을 사용합니다.\n",
    "gcv = GroupKFold(n_splits=4) # 그룹 교차검증을 사용합니다.\n",
    "X = df_test.columns.tolist()\n",
    "\n",
    "# 계층적 교차 검증으로 검증합니다.\n",
    "def eval_model_cv(model):\n",
    "    return cross_validate(\n",
    "        model, df_train[X], df_train['failure'], cv=cv, scoring='roc_auc', \n",
    "        return_train_score=True\n",
    "    )\n",
    "# 그룹 교차 검증으로 검증합니다.\n",
    "def eval_model_gcv(model):\n",
    "    return cross_validate(\n",
    "        model, df_train[X], df_train['failure'], cv=gcv, scoring='roc_auc', \n",
    "        return_train_score=True, groups=df_train['product_code']\n",
    "    )\n",
    "\n",
    "# 모델을 선택하고, train 셋으로 학습, test로 제출 결과를 뽑아냅니다.\n",
    "def choose_model(model):\n",
    "    model.fit(df_train[X], df_train['failure'])\n",
    "    prd = model.predict_proba(df_test[X])[:, 1]\n",
    "    pd.DataFrame({\n",
    "        'failure': prd\n",
    "    }, index=df_test.index).to_csv('answer6.csv')\n",
    "    return prd\n",
    "\n",
    "df_ans = pd.read_csv('test_prob_ans.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d56d895a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'B' 'E'] ['C']\n",
      "['A' 'B' 'C'] ['E']\n",
      "['A' 'C' 'E'] ['B']\n",
      "['B' 'C' 'E'] ['A']\n"
     ]
    }
   ],
   "source": [
    "for train_idx, test_idx in gcv.split(df_train[X], df_train['failure'], groups=df_train['product_code']):\n",
    "    print(\n",
    "        df_train.iloc[train_idx]['product_code'].unique(),\n",
    "        df_train.iloc[test_idx]['product_code'].unique()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b7251aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([0.02523446, 0.01967311, 0.01565123, 0.01565051, 0.01565766]),\n",
       "  'score_time': array([0.00299335, 0.0020256 , 0.01559186, 0.01559186, 0.01558542]),\n",
       "  'test_score': array([0.58840017, 0.5909264 , 0.57725538, 0.61231432, 0.58375591]),\n",
       "  'train_score': array([0.59221214, 0.59124045, 0.59530826, 0.58642301, 0.59368373])},\n",
       " 0.590530435171204)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17']),\n",
    "    ('pt', 'passthrough', ['na_1'])\n",
    "])\n",
    "clf_lr = make_pipeline(ct, \n",
    "    LogisticRegression(\n",
    "        solver = 'lbfgs'\n",
    "    )\n",
    ")\n",
    "result = eval_model_cv(clf_lr)\n",
    "result, np.mean(result['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f489a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd = choose_model(clf_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c530c24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5883988309352517"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(df_ans['failure'], prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f816112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([0.01579094, 0.02072024, 0.01763535, 0.03124261]),\n",
       "  'score_time': array([0.        , 0.00398898, 0.        , 0.        ]),\n",
       "  'test_score': array([0.58822089, 0.58492694, 0.58894173, 0.59538985]),\n",
       "  'train_score': array([0.59262299, 0.59350682, 0.59192443, 0.58956962])},\n",
       " 0.5893698519267131)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/Test 구성과 유사하게 하니,\n",
    "# 실제 채점 결과와 계층적 교차검증보다 가깝습니다. \n",
    "result = eval_model_gcv(clf_lr)\n",
    "result, np.mean(result['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e9c4974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([0.06183243, 0.06248498, 0.07810616, 0.06586289, 0.0599103 ]),\n",
       "  'score_time': array([0.      , 0.      , 0.      , 0.004987, 0.      ]),\n",
       "  'test_score': array([0.58192954, 0.5891719 , 0.57115526, 0.61208137, 0.58374581]),\n",
       "  'train_score': array([0.5926737 , 0.59170395, 0.59499   , 0.58692047, 0.59377472])},\n",
       " 0.5876167763141719)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA + LogisticRegression 모델입니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading']),\n",
    "    ('std_pca', make_pipeline(StandardScaler(), PCA(n_components=7)) , ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['na_1', 'na_2'])\n",
    "])\n",
    "X_lr = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "clf_lr_2 = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "result = eval_model_cv(clf_lr_2)\n",
    "result, np.mean(result['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afa9a33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([0.751055  , 0.78743219, 0.78190827, 0.78105474]),\n",
       "  'score_time': array([0.1249702 , 0.12497139, 0.12497663, 0.12498283]),\n",
       "  'test_score': array([0.5827436 , 0.58031524, 0.58424684, 0.58467245]),\n",
       "  'train_score': array([0.63213667, 0.63584284, 0.63679302, 0.6299596 ])},\n",
       " 0.5829945338197152)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier 모델도 만들어 봅니다.  (좀더 튜닝했습니다.)\n",
    "# PCA도 넣어 봅니다.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_rf = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct = ColumnTransformer([\n",
    "    ('std_pca', make_pipeline(StandardScaler(), PCA(n_components=7)), X_rf),\n",
    "    ('pt', 'passthrough', ['loading', 'na_1', 'na_2'])\n",
    "])\n",
    "clf_rf = make_pipeline(ct, RandomForestClassifier(\n",
    "    n_estimators=150, max_depth=7, min_samples_split= 512, random_state=123, n_jobs=4\n",
    "))\n",
    "result = eval_model_gcv(clf_rf)\n",
    "result,  np.mean(result['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72c114b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([2.28295064, 2.31192613, 2.28074241, 2.29630136]),\n",
       "  'score_time': array([0.03124142, 0.0312438 , 0.01562238, 0.01562309]),\n",
       "  'test_score': array([0.58401089, 0.58209848, 0.58241511, 0.59154288]),\n",
       "  'train_score': array([0.60348145, 0.60425951, 0.60456887, 0.60260103])},\n",
       " 0.5850168400222092)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost로 해봅니다.\n",
    "import xgboost as xgb\n",
    "X_xgb = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct = ColumnTransformer([\n",
    "    ('pt', 'passthrough', X_xgb)\n",
    "])\n",
    "clf_xgb = xgb.XGBClassifier(learning_rate=0.01, n_estimators=300, max_depth=2, random_state=123)\n",
    "clf_xgb = make_pipeline(ct, clf_xgb)\n",
    "result = eval_model_gcv(clf_xgb)\n",
    "result,  np.mean(result['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cdb6f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([0.96959281, 0.97944617, 0.98414373, 0.96852136]),\n",
       "  'score_time': array([0.01562309, 0.01562214, 0.01562238, 0.01562214]),\n",
       "  'test_score': array([0.58394407, 0.58068345, 0.5846679 , 0.59357819]),\n",
       "  'train_score': array([0.59490185, 0.59741658, 0.59562136, 0.59252278])},\n",
       " 0.5857184027349147)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GradientBoosting 모델을 만들어 봅니다.\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "X_gb = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct = ColumnTransformer([\n",
    "    ('pt', 'passthrough', X_gb)\n",
    "])\n",
    "clf_gb = make_pipeline(ct, GradientBoostingClassifier(\n",
    "    n_estimators=100, max_depth=2, learning_rate=0.01, random_state=123\n",
    "))\n",
    "result = eval_model_gcv(clf_gb)\n",
    "result,  np.mean(result['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6885b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([0.58997488, 0.61275887, 0.56079626, 0.59363747]),\n",
       "  'score_time': array([0.        , 0.00444078, 0.        , 0.        ]),\n",
       "  'test_score': array([0.58419268, 0.58659698, 0.58761482, 0.58167056]),\n",
       "  'train_score': array([0.59506176, 0.59357187, 0.59179506, 0.59154855])},\n",
       " 0.5850187607866695)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi-Layer-Perceptron으로 해봅니다.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17']),\n",
    "    ('pt', 'passthrough', ['na_1'])\n",
    "])\n",
    "clf_mlp = make_pipeline(ct, \n",
    "    MLPClassifier(\n",
    "        hidden_layer_sizes=[4],\n",
    "        random_state=123\n",
    "    )\n",
    ")\n",
    "result = eval_model_gcv(clf_mlp)\n",
    "result,  np.mean(result['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09a6a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline입니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17']),\n",
    "    ('pt', 'passthrough', ['na_1'])\n",
    "])\n",
    "X_lr = ['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17', 'na_1']\n",
    "clf_lr_1 = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "# PCA + LogisticRegression 모델입니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading']),\n",
    "    ('std_pca', make_pipeline(StandardScaler(), PCA(n_components=7)) , ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['na_1', 'na_2'])\n",
    "])\n",
    "X_lr = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "clf_lr_2 = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "# GradientBoosting 모델입니다.\n",
    "X_gb = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct = ColumnTransformer([\n",
    "    ('pt', 'passthrough', X_gb)\n",
    "])\n",
    "clf_gb = make_pipeline(ct, GradientBoostingClassifier(\n",
    "    n_estimators=100, max_depth=2, learning_rate=0.01, random_state=123\n",
    "))\n",
    "\n",
    "# Random Forest 입니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('std_pca', make_pipeline(StandardScaler(), PCA(n_components=7)), ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['loading', 'na_1', 'na_2'])\n",
    "])\n",
    "clf_rf = make_pipeline(ct, RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=7, min_samples_split= 512, random_state=123\n",
    "))\n",
    "\n",
    "# XGBoost 입니다.\n",
    "X_xgb = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct = ColumnTransformer([\n",
    "    ('pt', 'passthrough', X_xgb)\n",
    "])\n",
    "clf_xgb = make_pipeline(ct, xgb.XGBClassifier(\n",
    "    n_estimators=300, max_depth=2, learning_rate=0.01, random_state=123\n",
    "))\n",
    "\n",
    "# MLP 모델입니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17']),\n",
    "    ('pt', 'passthrough', ['na_1'])\n",
    "])\n",
    "clf_mlp = make_pipeline(ct, \n",
    "    MLPClassifier(\n",
    "        hidden_layer_sizes=[4],\n",
    "        random_state=123\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc331334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([5.28160286, 5.42056918, 5.65805578, 5.48310256]),\n",
       "  'score_time': array([0.07813454, 0.07810807, 0.07813406, 0.07810521]),\n",
       "  'test_score': array([0.58839276, 0.58575449, 0.58929202, 0.59346193]),\n",
       "  'train_score': array([0.60512637, 0.60647891, 0.60552289, 0.60304054])},\n",
       " 0.5892253004317329)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "X_vt = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)] \n",
    "# 모두 앙상블을 해봅니다. roc_auc에서 확률을 활용하므로 voting 을 soft로 합니다.\n",
    "clf_vt = VotingClassifier(\n",
    "    [\n",
    "        ('lr', clf_lr_1), #  Baseline\n",
    "        ('lr_2', clf_lr_2), # PCA + 속성 선택 모델 \n",
    "        ('gb', clf_gb), # GradientBoost\n",
    "        ('rf', clf_rf), # Random Forest\n",
    "        ('xgb', clf_xgb), # xgboost\n",
    "        ('mlp', clf_mlp) # MLP\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "result = eval_model_gcv(clf_vt)\n",
    "result,  np.mean(result['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd200f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5923370053956835"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd = choose_model(clf_vt)\n",
    "roc_auc_score(df_ans['failure'], prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e904b86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
